{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from decorators import measure_time\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import teaserpp_python\n",
    "\n",
    "\n",
    "# ######################################################################################\n",
    "# Carregamento e pré-processamento dos dados\n",
    "\n",
    "def load_point_cloud(file_path: str) -> o3d.geometry.PointCloud:\n",
    "    \"\"\"\n",
    "        Carrega um arquivo de ponto 3D em um objeto PointCloud.\n",
    "    \"\"\"\n",
    "    # Carrega nuvem de pontos a partir do arquivo especificado\n",
    "    cloud = o3d.io.read_point_cloud(file_path)\n",
    "    return cloud\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(cloud: o3d.geometry.PointCloud,\n",
    "                           voxel_size: int | float,\n",
    "                           verbose=False) -> o3d.geometry.PointCloud:\n",
    "    \"\"\"\n",
    "        Recebe uma nuvem de pontos e aplica o pre-processamento:\n",
    "        - Redimensiona a nuvem de pontos para o tamanho especificado;\n",
    "        - Calcula as normais;\n",
    "        Referência: https://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html#Extract-geometric-feature\n",
    "    \"\"\"\n",
    "    radius_normal = voxel_size * 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Redimensionando a nuvem de pontos para o tamanho {voxel_size:0.03f}.\")\n",
    "    cloud_downsampled = cloud.voxel_down_sample(voxel_size)\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Calculando as normais com busca de raio {radius_normal:0.03f}.\")\n",
    "    cloud_downsampled.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    return cloud_downsampled\n",
    "\n",
    "\n",
    "def compute_feature_descriptors(cloud: o3d.geometry.PointCloud,\n",
    "                                voxel_size: int | float,\n",
    "                                verbose=False) -> o3d.pipelines.registration.Feature:\n",
    "    \"\"\"\n",
    "        Recebe uma nuvem de pontos e aplica o descritor FPFH da biblioteca Open3D.\n",
    "        Referência: https://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html#Extract-geometric-feature\n",
    "    \"\"\"\n",
    "    radius_feature = voxel_size * 5\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Processando o descritor FPFH do `Open3D` com o raio de busca de {radius_feature:0.03f}\")\n",
    "    feature = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        cloud,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature,\n",
    "                                             max_nn=100))\n",
    "    return feature\n",
    "\n",
    "\n",
    "# ######################################################################################\n",
    "# Processamento dos dados com a biblioteca Open3D\n",
    "#     - Global registration usando RANSAC\n",
    "#     - Fast Global Registration\n",
    "#     - ICP com o método de ponto a ponto\n",
    "#     - ICP com o método de ponto a plano\n",
    "\n",
    "@measure_time\n",
    "def global_registration(source_cloud: o3d.geometry.PointCloud,\n",
    "                        target_cloud: o3d.geometry.PointCloud,\n",
    "                        source_features: o3d.pipelines.registration.Feature,\n",
    "                        target_features: o3d.pipelines.registration.Feature,\n",
    "                        voxel_size: int | float,\n",
    "                        verbose=False) -> o3d.pipelines.registration.RegistrationResult:\n",
    "    \"\"\"\n",
    "        Recebe uma par de nuvem de pontos, bem como seus descritores e realiza *global registration*.\n",
    "        Utiliza o método RANSAC da biblioteca Open3D.\n",
    "        Referência: https://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html#RANSAC\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    max_iteration = 100000\n",
    "    confidence = 0.999\n",
    "    if verbose:\n",
    "        print(\"Realiza o alinhamento grosseiro usando o método RANSAC.\")\n",
    "        print(f\"O raio de busca é {distance_threshold:0.03f}.\")\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_cloud, target_cloud, source_features, target_features, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ],\n",
    "        o3d.pipelines.registration.RANSACConvergenceCriteria(\n",
    "            max_iteration, confidence))\n",
    "    # Executa até atingir `max_iteration` ou `confidence`.\n",
    "    return result\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def fast_global_registration(source_cloud: o3d.geometry.PointCloud,\n",
    "                             target_cloud: o3d.geometry.PointCloud,\n",
    "                             source_features: o3d.pipelines.registration.Feature,\n",
    "                             target_features: o3d.pipelines.registration.Feature,\n",
    "                             voxel_size: int | float,\n",
    "                             verbose=False) -> o3d.pipelines.registration.RegistrationResult:\n",
    "    \"\"\"\n",
    "         Recebe uma par de nuvem de pontos, bem como seus descritores e realiza *fast global registration*.\n",
    "         Referência: https://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html#id2\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    if verbose:\n",
    "        print(\"Realiza o *fast global registration*.\")\n",
    "        print(f\"O raio de busca é {distance_threshold:0.03f}.\")\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "        source_cloud, target_cloud, source_features, target_features,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def fine_alignment_point_to_point(source_cloud: o3d.geometry.PointCloud,\n",
    "                                  target_cloud: o3d.geometry.PointCloud,\n",
    "                                  initial_transform,\n",
    "                                  voxel_size: int | float,\n",
    "                                  verbose=False) -> o3d.pipelines.registration.RegistrationResult:\n",
    "    \"\"\"\n",
    "        Recebe um par de nuvem de pontos, bem como uma transformação inicial para realizar um alinhamento fino.\n",
    "        Utiliza o método Point to Point da biblioteca Open3D.\n",
    "        Referência: https://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html#Local-refinement\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    if verbose:\n",
    "        print(\"Realizando o alinhamento com ICP - Point to Point\")\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source_cloud, target_cloud, distance_threshold,\n",
    "        initial_transform.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    return result\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def fine_alignment_point_to_plane(source_cloud: o3d.geometry.PointCloud,\n",
    "                                  target_cloud: o3d.geometry.PointCloud,\n",
    "                                  initial_transform,\n",
    "                                  voxel_size: int | float,\n",
    "                                  verbose=False) -> o3d.pipelines.registration.RegistrationResult:\n",
    "    \"\"\"\n",
    "        Recebe um par de nuvem de pontos, bem como uma transformação inicial para realizar um alinhamento fino.\n",
    "        Utiliza o método Point to Plane da biblioteca Open3D.\n",
    "        Referência: https://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html#Local-refinement\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    if verbose:\n",
    "        print(\"Realizando o alinhamento com ICP - Point to Plane com \")\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source_cloud, target_cloud, distance_threshold,\n",
    "        initial_transform.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n",
    "\n",
    "\n",
    "# ######################################################################################\n",
    "# Processamento dos dados com a biblioteca TEASER++\n",
    "# E algumas funções auxiliares necessárias.\n",
    "\n",
    "def pcd2xyz(pcd):\n",
    "    \"\"\"\n",
    "        Função auxiliar para converter um objeto PointCloud em um array numpy.\n",
    "        Usando em `establish_correspondences()`\n",
    "        Retirado de: https://github.com/MIT-SPARK/TEASER-plusplus/blob/master/examples/teaser_python_fpfh_icp/helpers.py\n",
    "    \"\"\"\n",
    "    return np.asarray(pcd.points).T\n",
    "\n",
    "\n",
    "def find_knn_cpu(feat0, feat1, knn=1, return_distance=False):\n",
    "    \"\"\"\n",
    "        Função auxiliar para executar `find_correspondences()`\n",
    "        Retirado de: https://github.com/MIT-SPARK/TEASER-plusplus/blob/master/examples/teaser_python_fpfh_icp/helpers.py\n",
    "    \"\"\"\n",
    "    # feat1tree = cKDTree(feat1) # Documentação recomenda usar KDTree em vez de cKDTree\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.cKDTree.html\n",
    "    feat1tree = KDTree(feat1)\n",
    "    # dists, nn_inds = feat1tree.query(feat0, k=knn, n_jobs=-1) # n_jobs=-1 is not supported in cKDTree\n",
    "    dists, nn_inds = feat1tree.query(feat0, k=knn, workers=-1)\n",
    "    if return_distance:\n",
    "        return nn_inds, dists\n",
    "    else:\n",
    "        return nn_inds\n",
    "\n",
    "\n",
    "def find_correspondences(feats0, feats1, mutual_filter=True):\n",
    "    \"\"\"\n",
    "        Função necessária para executar `establish_correspondences()`\n",
    "        Retirado de: https://github.com/MIT-SPARK/TEASER-plusplus/blob/master/examples/teaser_python_fpfh_icp/helpers.py\n",
    "    \"\"\"\n",
    "    nns01 = find_knn_cpu(feats0, feats1, knn=1, return_distance=False)\n",
    "    corres01_idx0 = np.arange(len(nns01))\n",
    "    corres01_idx1 = nns01\n",
    "\n",
    "    if not mutual_filter:\n",
    "        return corres01_idx0, corres01_idx1\n",
    "\n",
    "    nns10 = find_knn_cpu(feats1, feats0, knn=1, return_distance=False)\n",
    "    corres10_idx1 = np.arange(len(nns10))\n",
    "    corres10_idx0 = nns10\n",
    "\n",
    "    mutual_filter = (corres10_idx0[corres01_idx1] == corres01_idx0)\n",
    "    corres_idx0 = corres01_idx0[mutual_filter]\n",
    "    corres_idx1 = corres01_idx1[mutual_filter]\n",
    "    return corres_idx0, corres_idx1\n",
    "\n",
    "\n",
    "def establish_correspondences(source_cloud: o3d.geometry.PointCloud,\n",
    "                              target_cloud: o3d.geometry.PointCloud,\n",
    "                              source_features: o3d.pipelines.registration.Feature,\n",
    "                              target_features: o3d.pipelines.registration.Feature,\n",
    "                              verbose=False):\n",
    "    \"\"\"\n",
    "        Estabelece correspondências entre os pontos de uma nuvem de pontos.\n",
    "        Necessário para a função `robust_global_registration()`\n",
    "        Referência: https://github.com/MIT-SPARK/TEASER-plusplus/tree/master/examples/teaser_python_fpfh_icp#4-establish-putative-correspondences\n",
    "    \"\"\"\n",
    "\n",
    "    # Converte os descritores em arrays numpy\n",
    "    source_features_xyz = np.array(source_features.data).T\n",
    "    target_features_xyz = np.array(target_features.data).T\n",
    "\n",
    "    #\n",
    "    source_cloud_xyz = pcd2xyz(source_cloud)  # np array of size 3 by N\n",
    "    target_cloud_xyz = pcd2xyz(target_cloud)  # np array of size 3 by M\n",
    "\n",
    "    source_corrs, target_corrs = find_correspondences(source_features_xyz,\n",
    "                                                      target_features_xyz,\n",
    "                                                      mutual_filter=True)\n",
    "    source_corrs = source_cloud_xyz[:,\n",
    "                                    source_corrs]  # np array of size 3 by num_corrs\n",
    "    target_corrs = target_cloud_xyz[:,\n",
    "                                    target_corrs]  # np array of size 3 by num_corrs\n",
    "    if verbose:\n",
    "        num_corrs = source_corrs.shape[1]\n",
    "        print(f'FPFH gerou {num_corrs} correspondências.')\n",
    "    return source_corrs, target_corrs\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def robust_global_registration(source_corrs,\n",
    "                               target_corrs,\n",
    "                               voxel_size: int | float,\n",
    "                               verbose=False):\n",
    "    \"\"\"\n",
    "    Recebe uma par de nuvem de pontos, bem como seus descritores e realiza *global registration*.\n",
    "    Utiliza a biblioteca TEASER++.\n",
    "    Referência: https://github.com/MIT-SPARK/TEASER-plusplus/tree/master/examples/teaser_python_fpfh_icp\n",
    "    \"\"\"\n",
    "    noise_bound = voxel_size\n",
    "    if verbose:\n",
    "        print(\"Configurando os parâmetros do TEASER++.\")\n",
    "    solver_params = teaserpp_python.RobustRegistrationSolver.Params()\n",
    "    solver_params.cbar2 = 1.0\n",
    "    solver_params.noise_bound = noise_bound\n",
    "    solver_params.estimate_scaling = False\n",
    "    solver_params.inlier_selection_mode = teaserpp_python.RobustRegistrationSolver.INLIER_SELECTION_MODE.PMC_EXACT\n",
    "    solver_params.rotation_tim_graph = teaserpp_python.RobustRegistrationSolver.INLIER_GRAPH_FORMULATION.CHAIN\n",
    "    solver_params.rotation_estimation_algorithm = teaserpp_python.RobustRegistrationSolver.ROTATION_ESTIMATION_ALGORITHM.GNC_TLS\n",
    "    solver_params.rotation_gnc_factor = 1.4\n",
    "    solver_params.rotation_max_iterations = 10000\n",
    "    solver_params.rotation_cost_threshold = 1e-16\n",
    "    if verbose:\n",
    "        print(\"Realiza o alinhamento grosseiro usando o método TEASER++.\")\n",
    "    solver = teaserpp_python.RobustRegistrationSolver(solver_params)\n",
    "    solver.solve(source_corrs, target_corrs)\n",
    "    return solver.getSolution()\n",
    "\n",
    "\n",
    "def Rt2T(R, t):\n",
    "    \"\"\"\n",
    "        Função auxiliar para unir a solução rotacionar e solução linear em uma única matriz\n",
    "        Retirado de: https://github.com/MIT-SPARK/TEASER-plusplus/blob/master/examples/teaser_python_fpfh_icp/helpers.py\n",
    "    \"\"\"\n",
    "    T = np.identity(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZATION = False\n",
    "VERBOSE = False\n",
    "NUM_OF_EXEC = 1\n",
    "DATASETS = (o3d.data.DemoICPPointClouds(),)\n",
    "\n",
    "voxel_sizes = (0.05,)\n",
    "execution_times = {}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6461574",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_clouds = o3d.data.DemoICPPointClouds()\n",
    "\n",
    "source_cloud = o3d.io.read_point_cloud(demo_clouds.paths[0])\n",
    "target_cloud = o3d.io.read_point_cloud(demo_clouds.paths[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = 0.05\n",
    "source_down = preprocess_point_cloud(source_cloud, voxel_size, VERBOSE)\n",
    "target_down = preprocess_point_cloud(target_cloud, voxel_size, VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2488d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_features = compute_feature_descriptors(source_down, voxel_size, VERBOSE)\n",
    "target_features = compute_feature_descriptors(target_down, voxel_size, VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40932673",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gr = global_registration(source_down,\n",
    "                                        target_down,\n",
    "                                        source_features,\n",
    "                                        target_features,\n",
    "                                        voxel_size,\n",
    "                                        VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fgr = fast_global_registration(source_down,\n",
    "                                              target_down,\n",
    "                                              source_features,\n",
    "                                              target_features,\n",
    "                                              voxel_size,\n",
    "                                              VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RANSAC: {result_gr}\")\n",
    "print(f\"RANSAC: {result_gr.fitness}\")\n",
    "print(f\"RANSAC: {result_gr.inlier_rmse}\")\n",
    "print(f\"FGR: {result_fgr}\")\n",
    "print(f\"FGR: {result_fgr.fitness}\")\n",
    "print(f\"FGR: {result_fgr.inlier_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_gr_icp_point = fine_alignment_point_to_point(source_cloud,\n",
    "#                                                             target_cloud,\n",
    "#                                                             result_gr,\n",
    "#                                                             voxel_size,\n",
    "#                                                             VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_gr_icp_plane = fine_alignment_point_to_plane(source_cloud,\n",
    "#                                                             target_cloud,\n",
    "#                                                             result_gr,\n",
    "#                                                             voxel_size,\n",
    "#                                                             VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7258a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_fgr_icp_point = fine_alignment_point_to_point(source_cloud,\n",
    "#                                                              target_cloud,\n",
    "#                                                              result_fgr,\n",
    "#                                                              voxel_size,\n",
    "#                                                              VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_fgr_icp_plane = fine_alignment_point_to_plane(source_cloud,\n",
    "#                                                              target_cloud,\n",
    "#                                                              result_fgr,\n",
    "#                                                              voxel_size,\n",
    "#                                                              VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b14ab",
   "metadata": {},
   "source": [
    "# TEASER++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_corrs, target_corrs = establish_correspondences(source_cloud,\n",
    "                                                       target_cloud,\n",
    "                                                       source_features,\n",
    "                                                       target_features,\n",
    "                                                       VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d97580",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_teaser = robust_global_registration(source_corrs,\n",
    "                                           target_corrs,\n",
    "                                           voxel_size,\n",
    "                                           VERBOSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
